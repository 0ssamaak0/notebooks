{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run Dreambooth fine-tuned models for Stable Diffusion using dðŸ§¨ffusers \n",
        "\n",
        "This notebook allows you to run Stable Diffusion concepts trained via Dreambooth using ðŸ¤— Hugging Face [ðŸ§¨ Diffusers library](https://github.com/huggingface/diffusers). \n",
        "\n",
        "Train your own using [here](#) and navigate the [public library concepts](#) to pick yours. You may also want to use the [Spaces](#) to browse the library\n",
        "\n",
        "\n",
        "![Dreambooth Example](https://dreambooth.github.io/DreamBooth_files/teaser_static.jpg)\n",
        "_By using just 3-5 images you can teach new concepts to Stable Diffusion and personalize the model on your own images_ \n",
        "\n",
        "Differently from Textual Inversion, this approach trains the whole model, which can yield better results to the cost of bigger models.\n",
        "\n"
      ],
      "metadata": {
        "id": "0tb1ywtV_EEO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KFOytKQG-gGY"
      },
      "outputs": [],
      "source": [
        "#@title Install and import requirements\n",
        "!pip install diffusers transformers ftfy \n",
        "import diffusers\n",
        "from PIL import Image\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the model from the [Concepts Library](https://huggingface.co/sd-dreambooth-library). If you are new to Stable Diffusion, make sure you [read the LICENSE](https://github.com/CompVis/stable-diffusion/blob/main/LICENSE)\n",
        "#@markdown  You may also use a locally trained model by replacing the `model_id` to a path with the model locally or on Google Drive\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"sd-dreambooth-library/cat-toy\" #@param {type:\"string\"}\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZntPH3F6-myj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the Stable Diffusion pipeline with interactive UI Demo on Gradio\n",
        "import gradio as gr\n",
        "\n",
        "def inference(prompt, num_samples,num_rows):\n",
        "    all_images = [] \n",
        "    for _ in range(num_rows):\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            images = pipe([prompt] * num_samples, num_inference_steps=50, guidance_scale=7.5).images\n",
        "            all_images.extend(images)\n",
        "    return all_images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"prompt\")\n",
        "            samples = gr.Slider(label=\"Samples\",value=1)\n",
        "            rows = gr.Slider(label=\"Rows\",value=1)\n",
        "            run = gr.Button(value=\"Run\")\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery(show_label=False)\n",
        "\n",
        "    run.click(inference, inputs=[prompt,samples,rows], outputs=gallery)\n",
        "    gr.Examples([[\"a photo of sks toy riding a bicycle\", 1,1]], [prompt,samples,rows], gallery, inference, cache_examples=True)\n",
        "\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sUE8A7znAlvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the Stable Diffusion pipeline on Colab\n",
        "#@markdown Don't forget to use the `sks` token in your prompt\n",
        "\n",
        "from torch import autocast\n",
        "prompt = \"a photo of sks toy floating on a ramen bowl\" #@param {type:\"string\"}\n",
        "\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "num_rows = 2 #@param {type:\"number\"}\n",
        "\n",
        "all_images = [] \n",
        "for _ in range(num_rows):\n",
        "    with autocast(\"cuda\"):\n",
        "        images = pipe([prompt] * num_samples, num_inference_steps=50, guidance_scale=7.5).images\n",
        "        all_images.extend(images)\n",
        "\n",
        "grid = image_grid(all_images, num_samples, num_rows)\n",
        "grid"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DXBVVJjl_lwt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}